batch_size: 16
epoch: 200
learning_rate: 1e-3
gpu: 1
num_point: 10000
optimizer: AdamW
weight_decay: 1e-4
normal: True
lr_decay: 0.75
step_size: 50
model:
  nblocks: 4
  transformer_dim: 640
  group_size: 32

defaults:
  - model: Menghao

hydra:
  run:
    dir: log/normal/${model.name}

  sweep:
    dir: log/normal
    subdir: ${model.name}
